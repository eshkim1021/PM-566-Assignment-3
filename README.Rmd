---
title: "Assignment 3"
author: "Edward Kim"
date: "10/13/2020"
output: github_document
---

## APIs

```{r, message = FALSE}
library(tidyverse)
library(httr)
library(xml2)
library(dplyr)
library(tidytext)
library(ggplot2)
```



```{r}
#Get Number of Searchs 
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2+trial+vaccine")
counts <- xml2::xml_find_first(website,"/html/body/main/div[9]/div[2]/div[2]/div[1]/span")
counts <- as.character(counts)
stringr::str_extract(counts,"[0-9]+")

```
There were 560 results when the term "sars-cov-2 trial vaccine" was searched on the pubmed.gov website. 

```{r}
#Get the ids
query <- httr::GET(
  url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
  query = list(db = "pubmed",
               term = "sars-cov-2 trial vaccine",
               retmax = 1000
        )
)

query <- httr::content(query)
query_txt <- as.character(query)

ids <- stringr::str_extract_all(query_txt, "<Id>[0-9]+</Id>")[[1]]
ids <- stringr::str_remove_all(ids, "<Id>|</Id>")
```

```{r}
#Get all the papers that match IDs extracted
publication <- GET(
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
    query = list( db = "pubmed",
                  id = paste(ids,collapse = ","),
                  retmx = 1000,
                  rettype = "abstract"
        )
    )

publication <- httr::content(publication)
publication_txt <- as.character(publication)
```

The content of the publication was obtained through an API that matched all of the papers with the ids that were previously generated. 

```{r one-string-per-response, eval = TRUE}
pub_char_list <- xml2::xml_children(publication)
pub_char_list <- sapply(pub_char_list, as.character)
```



```{r}
titles <- str_extract(pub_char_list, "<ArticleTitle>(\\n|.)+</ArticleTitle>")
titles <- str_remove_all(titles, "</?[[:alnum:]]+>")
titles <- str_replace_all(titles,"\\s+"," ")

journal <- str_extract_all(pub_char_list,"<Title>([:alpha:]+ ?){10}</Title>")
journal <- str_remove_all(journal, "<Title>|</Title>")

date <- str_extract_all(pub_char_list,"<PubDate>(\\n|.)+</PubDate>")
date <- str_remove_all(date, "<PubDate>|<Year>|</Year>|<Month>|</Month>|<Day>|</Day>|</PubDate>")
date <-str_remove_all(date,"\n+|<MedlineDate>|</MedlineDate>")
date <- str_replace_all(date,"\\s+"," ")


abstracts <- str_extract(pub_char_list, "<Abstract>(\\n|.)+</Abstract>")
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]]+>")
abstracts <- str_replace_all(abstracts, "\\s+"," ")

```


All of the desired information (Pubmed ID number, Title of Paper, Name of Journal, Publication Date, and Abstract) was extracted through APIs and regular expressions. 

The table below shows the basic information regarding papers that show up under the term "sars-cov-2 trial vaccine."

```{r Create Data Frame}

database = data.frame(
  ID = ids,
  Title = titles,
  Journal = journal,
  Publication_Date= date,
  Abstract = abstracts
)

knitr::kable(database)

```

## Text Wrangling 

### Question 1:

#### With Stop Words

```{r}
#Loading the Dataset 
text <- read_csv("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/03_pubmed/pubmed.csv")
```

The abstracts were tokenized without removing stop words. The tokens that appeared most frequently are listed below:

```{r}
#Tokenizing the abstracts without removing stop words 
text %>% 
  unnest_tokens(token,abstract) %>% 
  count(token,sort = TRUE)%>% 
  top_n(10,n)

```

A majority of the most common tokens that are found were stop words, as expected. The only tokens that were not stop words were "covid" and "19." 

The abstracts were then tokenized after removing stop words, and grouped by the search term. 

#### Search Term: Covid

```{r}
text %>% 
  filter((term %in% "covid"))%>%
  unnest_tokens(token,abstract)%>%
  group_by(term)%>%
  anti_join(stop_words, by = c("token" = "word"))%>%
  count(token,sort = TRUE) %>%
  top_n(5,n)
  
```

For the search term "covid", the five most common tokens were: "covid","19","patients","disease,"pandemic". The most common tokens were all related to the Covid-19 pandemic that is happening currently. After removing the stop words, the tokens are more relevant to the search term. 

#### Search Term: Prostate Cancer

```{r}
text %>% 
  filter((term %in% "prostate cancer"))%>%
  unnest_tokens(token,abstract)%>%
  group_by(term) %>%
  anti_join(stop_words, by = c("token" = "word"))%>%
  count(token,sort = TRUE) %>%
  top_n(5,n)
```

For the search term "prostate cancer", the five most common tokens were: "cancer","prostate","patients","treatment","disease". All of these words were related to prostate cancer and the treament of the disease. After removing the stop words, the tokens were more related to prostate cancer. 

#### Search Term: Preeclampsia

```{r}
text %>% 
  filter((term %in% "preeclampsia"))%>%
  unnest_tokens(token,abstract)%>%
  group_by(term)%>%
  anti_join(stop_words, by = c("token" = "word"))%>%
  count(token,sort = TRUE) %>%
  top_n(5,n)
```

For the search term "preeclampsia," the five most common tokens were: "pre","eclampsia","preeclampsia","women","pregnancy". The most common tokens included the name of the disease. Preeclampsia is a conditions that occurs during pregnancy in women, which corresponds to both "women" and "pregnancy" being in the most common tokens. After removing the stop words, the tokens were more related to preeclampsia.

#### Search Term:Cystic Fibrosis

```{r}
text %>% 
  filter((term %in% "cystic fibrosis"))%>%
  unnest_tokens(token,abstract)%>%
  group_by(term)%>%
  anti_join(stop_words, by = c("token" = "word"))%>%
  count(token,sort = TRUE)%>%
  top_n(5,n)
```

For the search term "cystic fibrosis," the five most common tokens were: "fibrosis","cystic","cf","patients","disease". The most common stop words included the name of the disease itself, and referenced the patients that had the diseae. After removing the stop words, the tokens were more related to cystic fibrosis 

#### Search Term: Meningitis 

```{r}
text %>% 
  filter((term %in% "meningitis"))%>%
  unnest_tokens(token,abstract)%>%
  group_by(term)%>%
  anti_join(stop_words, by = c("token" = "word"))%>%
  count(token,sort = TRUE)%>%
  top_n(5,n)
```

For the search term "meningitis," the five most common tokens were: "patients","meningitis","meningeal", csf","clinical." The most common tokens include the word "patients" and things related to meningitis, as the excess buildup of csf (cerebral spinal fluid) lead to meningitis. After removing the stop words, the tokens were more related to meningitis. 

### Question 2: 

```{r}
text %>% 
  unnest_ngrams(ngram,abstract,n=2) %>%
  count(ngram,sort = TRUE) %>%
  top_n(10,n) %>%
  ggplot(aes(n,fct_reorder(ngram,n)))+
  geom_col()
  
```

Even though alot of the bigrams include stop words, there are some noticable data including the bigram "covid-19" is the most common bigram, alongside with "prostate cancer", and "pre eclampsia". This suggests that the previously named diseases are the most common diseases that were found through these search terms 

### Question 3: 

This table shows the TF-IDF values for each word-search term combination. 

```{r}
#Calculate the TF-IDF 
text%>% 
  unnest_tokens(token,abstract) %>% 
  count(token,term) %>% 
  bind_tf_idf(token,term,n)%>% 
  arrange(desc(tf_idf))
```

The 5 tokens with the highest TF-IDF value for the search term "covid" are: "covid","pandemic","cornovairus","sars","cov". These words vary significantly from just calculating the tokens with the highest frequency. This indicates that the words "coronavirus","sars", and "cov" appear lot of times in a couple of documents. 

The 5 tokens with the highest TF-IDF value for the search term "prostate cancer" are: "prostate","androgen","psa","prostatectomy","castration." These words also vary significnatly from just calculating the tokens with the highest frequency. This tokens include words that are highly related to prostate cancer, indicating that these words appear in only a couple of documents that are related to prostate cancer. 

The 5 tokens with the highest TF-IDF value for the search term "preeclampsia" are: "eclampsia" ,"preeclampsia","pregnancy","maternal","gestational". The words are similar to just calculating the tokens with the highest frequncy. However, the words "maternal" and "gestational" have high TF-IDF value, meaning that even though they may not be the most frequent, they appear only in a couple of documents presumably related to preeclampsia. 

The 5 tokens with the highest TF-IDF value for the search term "cystic fibrosis" are: "cf","fibrosis","cystic","ctfr","sweat". These words are also similar to just calculating the tokens with the highest frequncy. However, the words "ctfr" and "sweat" have a high TF-IDF value, meaning that they appear in high frequency in only a couple of documents 

The 5 tokens with the highest TF-IDF value for the search term "meningitis" are: "meningitis","pachymeningitis","csf","meninges","leptomeningeal". These words vary significantly from just calculating the tokens with hte highset frequency. This indicates that these words appear a lot in a couple of documents that are include specific informations and terms related to meningitis. 
